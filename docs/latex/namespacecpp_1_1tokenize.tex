\hypertarget{namespacecpp_1_1tokenize}{}\doxysection{cpp.\+tokenize Namespace Reference}
\label{namespacecpp_1_1tokenize}\index{cpp.tokenize@{cpp.tokenize}}
\doxysubsection*{Data Structures}
\begin{DoxyCompactItemize}
\item 
class \mbox{\hyperlink{classcpp_1_1tokenize_1_1_token}{Token}}
\end{DoxyCompactItemize}
\doxysubsection*{Functions}
\begin{DoxyCompactItemize}
\item 
def \mbox{\hyperlink{namespacecpp_1_1tokenize_ab78959b4d0a9c3bade98904a23129afc}{Get\+Tokens}} (source)
\item 
def \mbox{\hyperlink{namespacecpp_1_1tokenize_ae666c331b4bd7d1f3e8956c78cc6f3a4}{main}} (argv)
\end{DoxyCompactItemize}
\doxysubsection*{Variables}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{namespacecpp_1_1tokenize_a733f1cf605b1630fb6a0a7f30aaefbec}{V\+A\+L\+I\+D\+\_\+\+I\+D\+E\+N\+T\+I\+F\+I\+E\+R\+\_\+\+C\+H\+A\+RS}} = set(\+\_\+letters + \+\_\+letters.\+upper() + \textquotesingle{}\+\_\+0123456789\$\textquotesingle{})
\item 
\mbox{\hyperlink{namespacecpp_1_1tokenize_a8b45b0f0f2b504757e9ede9c342b2c36}{H\+E\+X\+\_\+\+D\+I\+G\+I\+TS}} = set(\textquotesingle{}0123456789abcdef\+A\+B\+C\+D\+EF\textquotesingle{})
\item 
\mbox{\hyperlink{namespacecpp_1_1tokenize_ad8c6dd06d4e6ef2e24e9186acb0aff43}{I\+N\+T\+\_\+\+O\+R\+\_\+\+F\+L\+O\+A\+T\+\_\+\+D\+I\+G\+I\+TS}} = set(\textquotesingle{}01234567890eE-\/+\textquotesingle{})
\item 
string \mbox{\hyperlink{namespacecpp_1_1tokenize_a0dfd65c08216eed29f74a64b603ac540}{U\+N\+K\+N\+O\+WN}} = \textquotesingle{}U\+N\+K\+N\+O\+WN\textquotesingle{}
\item 
string \mbox{\hyperlink{namespacecpp_1_1tokenize_a1655e62b60899059935930c81ba25c01}{S\+Y\+N\+T\+AX}} = \textquotesingle{}S\+Y\+N\+T\+AX\textquotesingle{}
\item 
string \mbox{\hyperlink{namespacecpp_1_1tokenize_a5e3bf1014a301906871113a989188a78}{C\+O\+N\+S\+T\+A\+NT}} = \textquotesingle{}C\+O\+N\+S\+T\+A\+NT\textquotesingle{}
\item 
string \mbox{\hyperlink{namespacecpp_1_1tokenize_aa14251ded979d72f93d7b234d8cfb584}{N\+A\+ME}} = \textquotesingle{}N\+A\+ME\textquotesingle{}
\item 
string \mbox{\hyperlink{namespacecpp_1_1tokenize_a3c8918ee13b9acf5ea4e70b484d67268}{P\+R\+E\+P\+R\+O\+C\+E\+S\+S\+OR}} = \textquotesingle{}P\+R\+E\+P\+R\+O\+C\+E\+S\+S\+OR\textquotesingle{}
\item 
\mbox{\hyperlink{namespacecpp_1_1tokenize_a8dd117207e391864f7d9cb656e826a9e}{W\+H\+E\+N\+C\+E\+\_\+\+S\+T\+R\+E\+AM}}
\item 
\mbox{\hyperlink{namespacecpp_1_1tokenize_ad02466a473c5e9c2ac256e18209f0967}{W\+H\+E\+N\+C\+E\+\_\+\+Q\+U\+E\+UE}}
\end{DoxyCompactItemize}


\doxysubsection{Function Documentation}
\mbox{\Hypertarget{namespacecpp_1_1tokenize_ab78959b4d0a9c3bade98904a23129afc}\label{namespacecpp_1_1tokenize_ab78959b4d0a9c3bade98904a23129afc}} 
\index{cpp.tokenize@{cpp.tokenize}!GetTokens@{GetTokens}}
\index{GetTokens@{GetTokens}!cpp.tokenize@{cpp.tokenize}}
\doxysubsubsection{\texorpdfstring{GetTokens()}{GetTokens()}}
{\footnotesize\ttfamily def cpp.\+tokenize.\+Get\+Tokens (\begin{DoxyParamCaption}\item[{}]{source }\end{DoxyParamCaption})}

\begin{DoxyVerb}Returns a sequence of Tokens.

Args:
  source: string of C++ source code.

Yields:
  Token that represents the next token in the source.
\end{DoxyVerb}
 

Definition at line 116 of file tokenize.\+py.

\mbox{\Hypertarget{namespacecpp_1_1tokenize_ae666c331b4bd7d1f3e8956c78cc6f3a4}\label{namespacecpp_1_1tokenize_ae666c331b4bd7d1f3e8956c78cc6f3a4}} 
\index{cpp.tokenize@{cpp.tokenize}!main@{main}}
\index{main@{main}!cpp.tokenize@{cpp.tokenize}}
\doxysubsubsection{\texorpdfstring{main()}{main()}}
{\footnotesize\ttfamily def cpp.\+tokenize.\+main (\begin{DoxyParamCaption}\item[{}]{argv }\end{DoxyParamCaption})}

\begin{DoxyVerb}Driver mostly for testing purposes.\end{DoxyVerb}
 

Definition at line 271 of file tokenize.\+py.



\doxysubsection{Variable Documentation}
\mbox{\Hypertarget{namespacecpp_1_1tokenize_a5e3bf1014a301906871113a989188a78}\label{namespacecpp_1_1tokenize_a5e3bf1014a301906871113a989188a78}} 
\index{cpp.tokenize@{cpp.tokenize}!CONSTANT@{CONSTANT}}
\index{CONSTANT@{CONSTANT}!cpp.tokenize@{cpp.tokenize}}
\doxysubsubsection{\texorpdfstring{CONSTANT}{CONSTANT}}
{\footnotesize\ttfamily string cpp.\+tokenize.\+C\+O\+N\+S\+T\+A\+NT = \textquotesingle{}C\+O\+N\+S\+T\+A\+NT\textquotesingle{}}



Definition at line 52 of file tokenize.\+py.

\mbox{\Hypertarget{namespacecpp_1_1tokenize_a8b45b0f0f2b504757e9ede9c342b2c36}\label{namespacecpp_1_1tokenize_a8b45b0f0f2b504757e9ede9c342b2c36}} 
\index{cpp.tokenize@{cpp.tokenize}!HEX\_DIGITS@{HEX\_DIGITS}}
\index{HEX\_DIGITS@{HEX\_DIGITS}!cpp.tokenize@{cpp.tokenize}}
\doxysubsubsection{\texorpdfstring{HEX\_DIGITS}{HEX\_DIGITS}}
{\footnotesize\ttfamily cpp.\+tokenize.\+H\+E\+X\+\_\+\+D\+I\+G\+I\+TS = set(\textquotesingle{}0123456789abcdef\+A\+B\+C\+D\+EF\textquotesingle{})}



Definition at line 41 of file tokenize.\+py.

\mbox{\Hypertarget{namespacecpp_1_1tokenize_ad8c6dd06d4e6ef2e24e9186acb0aff43}\label{namespacecpp_1_1tokenize_ad8c6dd06d4e6ef2e24e9186acb0aff43}} 
\index{cpp.tokenize@{cpp.tokenize}!INT\_OR\_FLOAT\_DIGITS@{INT\_OR\_FLOAT\_DIGITS}}
\index{INT\_OR\_FLOAT\_DIGITS@{INT\_OR\_FLOAT\_DIGITS}!cpp.tokenize@{cpp.tokenize}}
\doxysubsubsection{\texorpdfstring{INT\_OR\_FLOAT\_DIGITS}{INT\_OR\_FLOAT\_DIGITS}}
{\footnotesize\ttfamily cpp.\+tokenize.\+I\+N\+T\+\_\+\+O\+R\+\_\+\+F\+L\+O\+A\+T\+\_\+\+D\+I\+G\+I\+TS = set(\textquotesingle{}01234567890eE-\/+\textquotesingle{})}



Definition at line 42 of file tokenize.\+py.

\mbox{\Hypertarget{namespacecpp_1_1tokenize_aa14251ded979d72f93d7b234d8cfb584}\label{namespacecpp_1_1tokenize_aa14251ded979d72f93d7b234d8cfb584}} 
\index{cpp.tokenize@{cpp.tokenize}!NAME@{NAME}}
\index{NAME@{NAME}!cpp.tokenize@{cpp.tokenize}}
\doxysubsubsection{\texorpdfstring{NAME}{NAME}}
{\footnotesize\ttfamily string cpp.\+tokenize.\+N\+A\+ME = \textquotesingle{}N\+A\+ME\textquotesingle{}}



Definition at line 53 of file tokenize.\+py.

\mbox{\Hypertarget{namespacecpp_1_1tokenize_a3c8918ee13b9acf5ea4e70b484d67268}\label{namespacecpp_1_1tokenize_a3c8918ee13b9acf5ea4e70b484d67268}} 
\index{cpp.tokenize@{cpp.tokenize}!PREPROCESSOR@{PREPROCESSOR}}
\index{PREPROCESSOR@{PREPROCESSOR}!cpp.tokenize@{cpp.tokenize}}
\doxysubsubsection{\texorpdfstring{PREPROCESSOR}{PREPROCESSOR}}
{\footnotesize\ttfamily string cpp.\+tokenize.\+P\+R\+E\+P\+R\+O\+C\+E\+S\+S\+OR = \textquotesingle{}P\+R\+E\+P\+R\+O\+C\+E\+S\+S\+OR\textquotesingle{}}



Definition at line 54 of file tokenize.\+py.

\mbox{\Hypertarget{namespacecpp_1_1tokenize_a1655e62b60899059935930c81ba25c01}\label{namespacecpp_1_1tokenize_a1655e62b60899059935930c81ba25c01}} 
\index{cpp.tokenize@{cpp.tokenize}!SYNTAX@{SYNTAX}}
\index{SYNTAX@{SYNTAX}!cpp.tokenize@{cpp.tokenize}}
\doxysubsubsection{\texorpdfstring{SYNTAX}{SYNTAX}}
{\footnotesize\ttfamily string cpp.\+tokenize.\+S\+Y\+N\+T\+AX = \textquotesingle{}S\+Y\+N\+T\+AX\textquotesingle{}}



Definition at line 51 of file tokenize.\+py.

\mbox{\Hypertarget{namespacecpp_1_1tokenize_a0dfd65c08216eed29f74a64b603ac540}\label{namespacecpp_1_1tokenize_a0dfd65c08216eed29f74a64b603ac540}} 
\index{cpp.tokenize@{cpp.tokenize}!UNKNOWN@{UNKNOWN}}
\index{UNKNOWN@{UNKNOWN}!cpp.tokenize@{cpp.tokenize}}
\doxysubsubsection{\texorpdfstring{UNKNOWN}{UNKNOWN}}
{\footnotesize\ttfamily string cpp.\+tokenize.\+U\+N\+K\+N\+O\+WN = \textquotesingle{}U\+N\+K\+N\+O\+WN\textquotesingle{}}



Definition at line 50 of file tokenize.\+py.

\mbox{\Hypertarget{namespacecpp_1_1tokenize_a733f1cf605b1630fb6a0a7f30aaefbec}\label{namespacecpp_1_1tokenize_a733f1cf605b1630fb6a0a7f30aaefbec}} 
\index{cpp.tokenize@{cpp.tokenize}!VALID\_IDENTIFIER\_CHARS@{VALID\_IDENTIFIER\_CHARS}}
\index{VALID\_IDENTIFIER\_CHARS@{VALID\_IDENTIFIER\_CHARS}!cpp.tokenize@{cpp.tokenize}}
\doxysubsubsection{\texorpdfstring{VALID\_IDENTIFIER\_CHARS}{VALID\_IDENTIFIER\_CHARS}}
{\footnotesize\ttfamily cpp.\+tokenize.\+V\+A\+L\+I\+D\+\_\+\+I\+D\+E\+N\+T\+I\+F\+I\+E\+R\+\_\+\+C\+H\+A\+RS = set(\+\_\+letters + \+\_\+letters.\+upper() + \textquotesingle{}\+\_\+0123456789\$\textquotesingle{})}



Definition at line 40 of file tokenize.\+py.

\mbox{\Hypertarget{namespacecpp_1_1tokenize_ad02466a473c5e9c2ac256e18209f0967}\label{namespacecpp_1_1tokenize_ad02466a473c5e9c2ac256e18209f0967}} 
\index{cpp.tokenize@{cpp.tokenize}!WHENCE\_QUEUE@{WHENCE\_QUEUE}}
\index{WHENCE\_QUEUE@{WHENCE\_QUEUE}!cpp.tokenize@{cpp.tokenize}}
\doxysubsubsection{\texorpdfstring{WHENCE\_QUEUE}{WHENCE\_QUEUE}}
{\footnotesize\ttfamily cpp.\+tokenize.\+W\+H\+E\+N\+C\+E\+\_\+\+Q\+U\+E\+UE}



Definition at line 58 of file tokenize.\+py.

\mbox{\Hypertarget{namespacecpp_1_1tokenize_a8dd117207e391864f7d9cb656e826a9e}\label{namespacecpp_1_1tokenize_a8dd117207e391864f7d9cb656e826a9e}} 
\index{cpp.tokenize@{cpp.tokenize}!WHENCE\_STREAM@{WHENCE\_STREAM}}
\index{WHENCE\_STREAM@{WHENCE\_STREAM}!cpp.tokenize@{cpp.tokenize}}
\doxysubsubsection{\texorpdfstring{WHENCE\_STREAM}{WHENCE\_STREAM}}
{\footnotesize\ttfamily cpp.\+tokenize.\+W\+H\+E\+N\+C\+E\+\_\+\+S\+T\+R\+E\+AM}



Definition at line 58 of file tokenize.\+py.

